{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on Titanic Survivorship\n",
    "\n",
    "This notebook performs a simple logistic regression on the data from the Kaggle project on predicting survivorship of the passengers of the Titanic.  We also grade the results by using the full survivorship data that was downloaded from [Vanderbuilt Biostats](http://biostat.mc.vanderbilt.edu/wiki/Main/DataSets) from the file titanic3.csv\n",
    "\n",
    "It is important that the column names between these various csv's match and that the passenger names match as well so that we can perform table merges correctly.  The Kaggle data has capitalized column names while the Vanderbuilt does not, so I modified titanic3.csv so that, where appropriate, the column names match.\n",
    "\n",
    "Also, these two data sources treat embedded double quotes differently.  The Vanderbuilt data is consistent, but the Kaggle date is really borked on this one.  So I removed all embedded double quotes from the files.  This can be done by the following shell commands.\n",
    "\n",
    "    sed -e 's/\\\"\\\"\\\"\\\"\\\"/\\\"/g' -e 's/\\\"\\\"\\\"/\\\"/g' -e 's/\\\"\\\"//g' train.csv >train_mod.csv\n",
    "    sed -e 's/\\\"\\\"\\\"\\\"\\\"/\\\"/g' -e 's/\\\"\\\"\\\"/\\\"/g' -e 's/\\\"\\\"//g' test.csv >test_mod.csv\n",
    "\n",
    "Now for the code.  First the imports and a define of a custom exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class PredictionError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read in the data (eventually) using the pandas read_csv method.  I chose to read all of it in and clean it in a separate step.  That is done by this function, which is largely what the Kaggle Python code does (only a little less ugly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(tdf):\n",
    "    tdf['gender'] = tdf['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "    # Missing values will be filled with medians\n",
    "    tdf = tdf.fillna(tdf.median())\n",
    "\n",
    "    # Drop all the features that will not be used in logistic regression\n",
    "    tdf = tdf.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId',\n",
    "                    'Embarked'], axis=1)\n",
    "    return tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find out how accurate our predictions are and since we have the full survivorship data in titanic3.csv (or titanic3_mod.csv) we can do that.  Here we assume that we have a DataFrame that has the ground truth column as well as the prediction column.  We pass in the dataframe, the name of the ground truth column and the prediction column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_results(df, gt, pred):\n",
    "    \"\"\" Score the results in a DataFrame that has both the ground\n",
    "        truth and the prediction. gt is the name of the ground truth\n",
    "        column etc.  Return the raw accuracy, the precision and the recall.\n",
    "        Note that precision and recall are most useful for evaluating\n",
    "        predictions on rare events. \"\"\"\n",
    "    correct = df.ix[df[gt] == df[pred]]\n",
    "    incorrect = df.ix[df[gt] != df[pred]]\n",
    "    true_pos = len(correct.ix[correct[gt] == 1])\n",
    "    true_neg = len(correct.ix[correct[gt] == 0])\n",
    "    false_neg = len(incorrect.ix[incorrect[pred] == 0])\n",
    "    false_pos = len(incorrect.ix[incorrect[pred] == 1])\n",
    "\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    num_correct = len(correct)\n",
    "    tot_pred = len(df)\n",
    "    accuracy = num_correct / tot_pred\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read in the data, clean it, and before doing any training, we take a look at the correlation coefficients of the data. Not surprisingly, there is a wide range of correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Survived    Pclass       Age     SibSp     Parch      Fare    gender\n",
      "Survived  1.000000 -0.338481 -0.064910 -0.035322  0.081629  0.257307 -0.543351\n",
      "Pclass   -0.338481  1.000000 -0.339898  0.083081  0.018443 -0.549500  0.131900\n",
      "Age      -0.064910 -0.339898  1.000000 -0.233296 -0.172482  0.096688  0.081163\n",
      "SibSp    -0.035322  0.083081 -0.233296  1.000000  0.414838  0.159651 -0.114631\n",
      "Parch     0.081629  0.018443 -0.172482  0.414838  1.000000  0.216225 -0.245489\n",
      "Fare      0.257307 -0.549500  0.096688  0.159651  0.216225  1.000000 -0.182333\n",
      "gender   -0.543351  0.131900  0.081163 -0.114631 -0.245489 -0.182333  1.000000\n"
     ]
    }
   ],
   "source": [
    "trdf = pd.read_csv(\"train_mod.csv\", header=0)\n",
    "trdf = clean_data(trdf)\n",
    "print(trdf.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the pairwise correlation for **Survived** is high for **Pclass**, **Fare**, and **gender**, but much smaller for the others.  Now we are ready to train a Logistic and see how well it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7655502392344498   precision: 0.6973684210526315   recall: 0.6708860759493671\n"
     ]
    }
   ],
   "source": [
    "train = trdf.values\n",
    "logit = LogisticRegression()\n",
    "logit.fit(train[:, 1:], train[:, 0])\n",
    "\n",
    "testdf = pd.read_csv(\"test_mod.csv\", header=0)\n",
    "pass_survival = testdf.copy()\n",
    "testdf = clean_data(testdf)\n",
    "\n",
    "c = logit.predict(testdf.values)\n",
    "\n",
    "# add the survival prediction column\n",
    "pass_survival['pred_survival'] = c\n",
    "\n",
    "# Get the ground truth dataset\n",
    "gtdf = pd.read_csv(\"titanic3_mod.csv\", header=0)\n",
    "\n",
    "# Now merge the predictions with the ground truth.  This\n",
    "# is like a table join in the database world.\n",
    "ansdf = pd.merge(gtdf, pass_survival)\n",
    "\n",
    "# check to see if we got all the answers\n",
    "if len(pass_survival) != len(ansdf):\n",
    "    raise PredictionError(\"Did not match all predictions with ground truth\")\n",
    "\n",
    "accuracy, precision, recall = score_results(ansdf, 'Survived', \n",
    "                                                'pred_survival')\n",
    "\n",
    "print(\"accuracy: {}   precision: {}   recall: {}\".format(accuracy,\n",
    "           precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We forgot to see how well this model does on the training data itself.  Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8183738120380147   precision: 0.7681660899653979   recall: 0.6788990825688074\n"
     ]
    }
   ],
   "source": [
    "m = logit.predict(train[:, 1:])\n",
    "m_surv = trdf.copy()\n",
    "m_surv['pred_survival'] = m\n",
    "\n",
    "moddf = pd.merge(gtdf, m_surv)\n",
    "a, p, r = score_results(moddf, 'Survived', 'pred_survival')\n",
    "print(\"accuracy: {}   precision: {}   recall: {}\".format(a, p, r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we do get the expected results that the model performs better on the training data than on the test data.  But it is not that much better.  This shows that whoever did the data partitioning, did a reasonibly good (or random) job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
